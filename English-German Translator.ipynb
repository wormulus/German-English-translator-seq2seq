{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4d60d8",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0198d266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '$', '%', ',', '-', '.', '00', '10', '100', '12', '13', '1374', '15', '17', '18', '19', '1960', '2', '20', '2009', '2013', '223', '25', '3', '30', '300', '4', '42', '45', '5', '50', '6', '65', '7', '8', '83', '839', '9', '911', '92', '99', ':', '?', 'A', 'ATM', 'Abandon', 'About', 'Accidents', 'Act'] Abk√ºrzung\n",
      "['!', '\"', '$', '%', ',', '-', '.', '00', '10', '100', '12', '13', '1374', '15', '17', '18', '19', '1960', '2', '20', '2009', '2013', '223', '25', '3', '30', '300', '4', '42', '45', '5', '50', '6', '65', '7', '8', '83', '839', '9', '911', '92', '99', ':', '?', 'A', 'ATM', 'Abandon', 'About', 'Accidents', 'Act', 'Add', 'Adjust', 'Admission', 'After', 'Aim', \"Ain't\", 'Air', 'Alcohol', 'All', 'Allow', 'Am', 'America', 'American', 'Ammonia', 'An', 'Answer', 'Any', 'Anybody', 'Anyone', 'Anything', 'Apologize', 'Apples', 'Aquarius', 'Arabic', 'Arabs', 'Are', \"Aren't\", 'Asia', 'Asian', 'Ask', 'At', 'Atlantis', 'Attack', 'Attention', 'Australia', 'Austrian', 'Autumn', 'Avoid', 'Awesome', 'BMW', 'Bach', 'Back', 'Baking', 'Balls', 'Be', 'Bears', 'Beat', 'Beef', \"Beer's\", 'Bees', 'Begin', 'Behave', 'Beware', 'Birds', 'Bite', 'Black', 'Bless', 'Blow', 'Boats', 'Boil', 'Bolt', 'Boston', 'Both', 'Bottoms', 'Boys', 'Brace', 'Brazil', 'Break', 'Breathe', 'Bring', 'British', 'Brush', 'Bugs', 'Burn', 'Bury', 'Business', 'Buy', 'CD', 'CDs', 'CNN', 'Cain', 'Call', 'Calm', 'Can', \"Can't\", 'Canadian', 'Canadians', 'Carry', 'Catch', 'Catholic', 'Cats', 'Caucasian', 'Champagne', 'Change', 'Check', 'Cheer', 'Cheers', 'Cherries', 'Chess', 'Chicken', 'Chill', 'Chinese', 'Choose', 'Christian', 'Christmas', 'Chuck', 'Clap', 'Classes', 'Clean', 'Clear', 'Click', 'Clip', 'Close', 'Cocaine', 'Coffee', 'Comb', 'Come', 'Comfort', 'Compare', 'Concentrate', 'Congratulations', 'Consider', 'Contact', 'Continue', 'Control', 'Cook', 'Cool', 'Copy', 'Could', \"Couldn't\", 'Count', \"Court's\", 'Cover', 'Cows', 'Crime', 'Cross', 'Crows', 'Crying', 'Cuff', 'Customs', 'Cut', 'D', 'DJ', 'DUIs', 'DVD', 'Dad', 'Dance', 'Danish', 'Deal', 'Death', 'Defend', 'Definitely', 'Describe', 'Destroy', 'Did', \"Didn't\", 'Dig', 'Dinner', \"Dinner's\", 'Disable', 'Do', 'Does', \"Doesn't\", 'Dogs', \"Don't\", 'Dr', 'Draw', 'Dreams', 'Dress', 'Drink', 'Drinks', 'Drive', 'Drop', 'Dry', 'Duck', 'Dude', 'Duty', 'Easter', 'Easy', 'Eat', 'Egypt', 'Empty', 'English', 'Enjoy', 'Enough', 'Enter', 'Ethiopian', 'Even', 'Everybody', \"Everybody's\", 'Everyone', \"Everyone's\", 'Everything', \"Everything's\", 'Examine', 'Excuse', 'Exhale', 'Explain', 'FBI', 'Face', 'Family', 'Fantastic', 'Feed', 'Feel', 'Fetch', 'Fight', 'Fill', 'Find', 'Finish', 'Fire', 'Fish', 'Fishing', 'Fix', 'Flies', 'Flip', 'Flowers', 'Flying', 'Fold', 'Follow', 'Food', 'For', 'Ford', 'Forget', 'Forgive', 'Form', 'France', 'Freeze', 'French', 'Frenchman', 'Friday', 'Frogs', 'Fry', 'Gas', 'German', 'Get', 'Ghosts', 'Gifu', 'Girls', 'Give', 'Glass', 'Go', 'God', 'Golf', 'Good', 'Goodbye', 'Goodnight', 'Gophers', 'Got', 'Grab', 'Great', 'Green', 'Grow', 'Guess', 'Guys', 'Halloween', 'Hamlet', 'Hand', 'Hands', 'Hang', 'Happy', 'Harvard', 'Has', 'Have', 'He', \"He's\", 'Head', 'Heaven', 'Helium', 'Hello', 'Help', 'Hens', 'Her', 'Here', \"Here's\", 'Hey', 'Hi', 'Hide', 'His', 'Hit', 'Hoist', 'Hold', 'Honesty', 'Hop', 'How', \"How'd\", \"How're\", \"How's\", 'Hug', 'Humans', 'Humor', 'Hurry', 'Hypnotism', 'I', \"I'd\", \"I'll\", \"I'm\", \"I've\", 'ID', 'Ice', 'Ignore', 'Input', 'Internet', 'Iron', 'Is', \"Isn't\", 'It', \"It'll\", \"It's\", 'Italy', 'Jackson', 'Japan', 'Japanese', 'Jeep', 'Jesus', 'Jewish', 'Join', 'Jump', 'Just', 'Keep', 'Kids', 'Kill', 'Kiss', 'Kissing', 'Knead', 'Koalas', 'Korean', 'Kyoto', 'Ladies', 'Large', 'Latin', 'Lead', 'Learn', 'Leave', 'Lemons', 'Lend', 'Let', \"Let's\", 'Lie', 'Life', \"Life's\", 'Light', 'Listen', 'Live', 'Lock', 'Look', 'Loosen', 'Lord', 'Louder', 'Love', 'Lower', 'Lunch', 'Lying', 'Mail', 'Make', 'Mama', 'Man', 'Many', 'Marry', 'Mars', 'Mary', \"Mary's\", 'Math', 'May', 'Maybe', 'Me', 'Meat', 'Meet', 'Memorize', 'Men', 'Merry', 'Might', 'Mine', 'Mistakes', 'Mom', \"Mom's\", 'Monday', 'Mondays', 'Money', 'More', 'Motion', 'Move', 'Mow', \"Mum's\", 'Muslim', 'Must', 'My', 'Nature', 'Neither', 'Never', 'New', 'Nice', 'Night', 'No', 'Nobody', \"Nobody'll\", \"Nobody's\", 'None', 'Norway', 'Nothing', 'Now', 'Nowhere', 'OCD', 'OK', 'Obey', 'October', 'Of', 'Oh', 'Once', 'Only', 'Open', 'Our', 'Ow', 'Owls', 'PTSD', 'Pack', 'Paint', 'Pandas', 'Pardon', 'Paris', 'Park', 'Parties', 'Pass', 'Peel', 'People', 'Perfect', 'Perhaps', 'Perth', 'Ph', 'PhD', 'Phone', 'Picasso', 'Pick', 'Pigs', 'Pisces', 'Place', 'Plants', 'Play', 'Please', 'Praise', 'Prepare', 'Press', 'Prices', 'Prove', 'Pull', 'Pump', 'Push', 'Put', 'Puzzles', 'Quiet', 'Quit', 'Rabbits', 'Rain', 'Raise', 'Read', 'Reality', 'Really', 'Record', 'Red', 'Rejection', 'Relax', 'Release', 'Remain', 'Remember', 'Remove', 'Repeat', 'Replace', 'Respect', 'Rest', 'Return', 'Revenge', 'Roll', 'Rome', 'Room', 'Rules', 'Run', 'Russia', 'Sailing', 'Saturday', 'Saturdays', 'Saturn', 'Save', 'Say', 'School', \"School's\", 'Science', 'Scoot', 'Seals', 'Secure', 'See', 'Seize', 'Send', 'Seriously', 'Set', 'Shall', 'Shame', 'Sharks', 'She', \"She's\", 'Shoo', 'Shoot', 'Should', 'Show', 'Shut', 'Sign', 'Silence', 'Silk', 'Sing', 'Sit', 'Size', 'Smell', 'Smile', 'Smoking', 'Snakes', 'Snap', 'So', 'Some', 'Somebody', 'Someone', \"Someone's\", 'Something', \"Something's\", 'Sorry', 'Spanish', 'Speak', 'Speed', 'Spelling', 'Spiders', 'Spit', 'Spread', 'Spring', 'Stand', 'Start', 'Stay', 'Steal', 'Step', 'Stick', 'Stir', 'Stop', 'Straighten', 'Study', 'Sugar', 'Suit', 'Summer', \"Summer's\", 'Sunday', 'Sundays', 'Superman', 'Supper', 'Surprise', 'Swallow', 'Sweep', 'Sweet', 'Swimming', 'Swiss', 'TB', 'TV', \"TV's\", 'Take', 'Talk', 'Taste', 'Tastes', 'Tea', 'Tell', 'Terrific', 'Thank', 'Thanks', 'That', \"That'd\", \"That'll\", \"That's\", 'The', 'Their', 'Then', 'There', \"There's\", 'These', 'They', \"They'd\", \"They'll\", \"They're\", \"They've\", 'Thief', 'Things', 'Think', 'This', \"This'll\", 'Those', 'Throw', 'Time', \"Time's\", 'Times', 'To', 'Today', \"Today's\", 'Tokyo', 'Tom', \"Tom'll\", \"Tom's\", 'Tomatoes', 'Too', 'Torture', 'Toss', 'Touch', 'Tough', 'Toyota', 'Translate', 'Trust', 'Try', 'Turn', 'Turtles', 'Twitter', 'UFO', 'US', 'Unbelievable', 'Unlock', 'Unscrew', 'Use', 'Vote', 'Wait', 'Wake', 'Walk', 'Walking', 'Walls', 'War', 'Warn', 'Was', 'Wash', \"Wasn't\", 'Watch', 'Water', 'Wax', 'Way', 'We', \"We'd\", \"We'll\", \"We're\", \"We've\", 'Weak', 'Wednesday', 'Welcome', 'Well', 'Were', 'What', \"What'll\", \"What's\", \"What've\", 'Whatever', 'When', \"When's\", 'Where', \"Where's\", 'Which', 'Who', \"Who'd\", \"Who'll\", \"Who's\", 'Whose', 'Why', \"Why's\", 'Wiggle', 'Will', 'Wind', 'Winter', 'Wipe', 'Wish', 'Wolves', 'Women', \"Won't\", 'Wonderful', 'Wood', 'Wool', 'Work', 'Would', 'Wow', 'Write', 'Year', 'Years', 'Yes', 'Yolks', 'You', \"You'd\", \"You'll\", \"You're\", \"You've\", 'Your', 'Yours', 'a', 'aah', 'abandoned', 'abated', 'abhor', 'able', 'aboard', 'about', 'abroad', 'absent', 'absurd', 'abusive', 'accelerated', 'accept', 'acceptable', 'accurate', 'ache', 'ached', 'aches', 'acne', 'acquitted', 'across', 'act', 'acted', 'action', 'active', 'actor', 'actors', 'acts', 'adamant', 'adaptable', 'added', 'addict', 'addicted', 'adjourned', 'admirable', 'admire', 'admired', 'admires', 'admit', 'admitted', 'adopted', 'adorable', 'adore', 'adored', 'adores', 'adult', 'adults', 'adventure', 'adventurous', 'advice', 'advises', 'affair', 'afford', 'afraid', 'after', 'afternoon', 'again', 'against', 'age', 'ages', 'aggressive', 'agile', 'agitated', 'agnostic', 'ago', 'agony', 'agree', 'agreed', 'agrees', 'ahead', 'aid', \"ain't\", 'air', 'alarm', 'alarmed', 'album', 'alert', 'alerted', 'alibi', 'alike', 'alive', 'all', 'allergies', 'allow', 'allowed', 'almonds', 'almost', 'alone', 'along', 'aloud', 'already', 'also', 'alto', 'always', 'am', 'amazed', 'amazing', 'ambidextrous', 'ambition', 'ambitious', 'ambulance', 'ambush', 'amnesia', 'amuse', 'amused', 'amusing', 'an', 'and', 'anemic', 'angel', 'angry', 'animal', 'animals', 'annoy', 'annoyed', 'annoying', 'annoys', 'anorexic', 'another', 'answer', 'answered', 'answers', 'ants', 'anxious', 'any', 'anybody', 'anyone', 'anything', 'anyway', 'apart', 'apologize', 'apologized', 'apologizing', 'app', 'appalled', 'appear', 'appears', 'applauded', 'apple', 'apples', 'appreciate', 'approached', 'approve', 'approved', 'approves', 'architects', 'are', 'area', \"aren't\", 'argue', 'arguing', 'arm', 'armed', 'arms', 'army', 'around', 'arrest', 'arrested', 'arrived', 'arrogant', 'art', 'article', 'artist', 'artistic', 'as', 'ashamed', 'aside', 'ask', 'asked', 'asking', 'asleep', 'aspirin', 'assertive', 'assist', 'assistant', 'assume', 'assumed', 'asthma', 'astonished', 'astrology', 'astronomy', 'at', 'ate', 'atheist', 'athletic', 'attack', 'attacked', 'attend', 'attention', 'attentive', 'attic', 'attorney', 'aunt', 'author', 'autistic', 'autumn', 'available', 'average', 'avoidable', 'avoided', 'avoiding', 'avoids', 'awake', 'away', 'awesome', 'awful', 'awfully', 'awkward', 'babbling', 'babe', 'babies', 'baby', \"baby's\", 'bachelor', 'back', 'backed', 'backup', 'backward', 'bacon', 'bad', 'badly', 'baffled', 'bag', \"bag's\", 'bagel', 'bags', 'bail', 'bake', 'baked', 'baker', 'bakes', 'baking', 'bald', 'ball', 'balmy', 'banana', 'bananas', 'band', 'bank', 'bankrupt', 'banned', 'bar', 'barbaric', 'barber', 'barefoot', 'barely', 'bargain', 'bark', 'barked', 'barking', 'base', 'baseball', 'bashful', 'bat', 'bath', 'battery', 'be', 'beach', 'beaks', 'beans', 'bear', 'beard', 'beardless', 'beat', 'beaten', 'beats', 'beautiful', 'beauty', 'became', 'become', 'bed', 'bedbugs', 'beds', 'bedtime', 'beef', 'been', 'beer', \"beer's\", 'before', 'beg', 'began', 'begging', 'begin', 'beginner', 'begun', 'behaved', 'behind', 'being', 'belched', 'believe', 'believed', 'believes', 'bell', 'belong', 'belongs', 'below', 'bench', 'bent', 'berserk', 'beside', 'best', 'bet', 'betrayed', 'bets', 'better', 'between', 'beyond', 'biased', 'bicycle', 'big', 'bigger', 'bigot', 'bigwig', 'bike', \"bike's\", 'biked', 'biker', 'biking', 'bilingual', 'bill', 'bills', 'biologist', 'bird', 'birds', 'birthday', 'bit', 'bite', 'bites', 'bitter', 'bizarre', 'black', 'blacked', 'blame', 'blamed', 'blames', 'blanket', 'blast', 'bleated', 'bled', 'bleeding', 'bless', 'blew', 'blind', 'blinded', 'blink', 'blinked', 'blog', 'blond', 'blonde', 'blood', 'bloom', 'blown', 'blue', 'blues', 'bluff', 'bluffing', 'blushed', 'blushing', 'board', 'boat', 'bogus', 'boiling', 'bomb', 'bonkers', 'book', \"book's\", 'booked', 'books', 'boots', 'bore', 'bored', 'bores', 'boring', 'born', 'borrow', 'boss', 'bossy', 'botanist', 'both', 'bother', 'bottle', 'bought', 'bow', 'bowed', 'bowl', 'box', 'boxes', 'boy', 'boys', 'braces', 'brag', 'bragging', 'brain', 'brains', 'braked', 'brakes', 'brand', 'brat', 'brave', 'bread', 'break', 'breakfast', 'breathe', 'breathing', 'brews', 'bridge', 'brief', 'briefly', 'bright', 'brilliant', 'bring', 'broccoli', 'broke', 'broken', 'broom', 'brother', 'brothers', 'brought', 'brown', 'brush', 'bucket', 'buddy', 'budge', 'bug', 'bugs', 'build', 'built', 'bulky', 'bull', 'bullet', 'bullied', 'bully', 'bummed', 'burned', 'burns', 'burp', 'burped', 'bury', 'bus', 'business', 'busker', 'busted', 'busy', 'butcher', 'butler', 'button', 'buy', 'buying', 'by', 'cab', 'cafe', 'caffeine', 'cage', 'cake', 'call', 'called', 'calling', 'callous', 'calls', 'calm', 'calmed', 'calmly', 'came', 'camel', 'camels', 'camera', 'cameramen', 'camp', 'can', \"can't\", 'cancel', 'canceled', 'cancer', 'candle', 'candles', 'candy', 'cannot', 'cap', 'capsized', 'captured', 'car', \"car's\", 'card', 'cards', 'care', 'cared', 'careful', 'carefully', 'careless', 'cares', 'carpenter', 'carrots', 'carry', 'cars', 'cartoons', 'case', 'cash', 'cast', 'castles', 'cat', 'catch', 'catching', 'cats', 'cattle', 'caught', 'caused', 'causes', 'caution', 'cautious', 'cautiously', 'caviar', 'celebrating', 'celery', 'census', 'certain', 'chair', 'chance', 'chances', 'change', 'changed', 'changes', 'charge', 'charisma', 'charm', 'charmer', 'charming', 'chased', 'chatting', 'chauffeur', 'cheap', 'cheaper', 'cheat', 'cheated', 'cheating', 'cheats', 'check', 'checked', 'checking', 'cheered', 'cheerful', 'cheering', 'cheese', 'chef', 'chemistry', 'chess', 'chest', 'chew', 'chewing', 'chicken', 'chickens', 'chickpeas', 'chief', 'child', 'childish', 'children', 'chili', 'chilly', 'chip', 'chocolate', 'choice', 'choked', 'choking', 'choose', 'choosy', 'chose', 'chubby', 'chuckled', 'church', 'circle', 'citizen', 'city', 'clap', 'clapped', 'clapping', 'claps', 'class', 'classic', 'classmates', 'clean', 'clear', 'clearing', 'clearly', 'clerk', 'clever', 'client', 'climbed', 'climbing', 'clock', 'clocks', 'close', 'closed', 'closely', 'closer', 'cloudy', 'clue', 'clueless', 'clumsy', 'coach', 'coat', 'coffee', 'cognac', 'coin', 'coke', 'cold', 'collect', 'college', 'colonel', 'color', 'coma', 'comb', 'come', 'comedian', 'comedies', 'comes', 'comfortable', 'comics', 'coming', 'command', 'comment', 'committed', 'communist', 'company', 'competent', 'complain', 'complained', 'complaining', 'complex', 'complicated', 'computer', 'computers', 'con', 'conceited', 'conceivable', 'concentrated', 'concerned', 'confess', 'confessed', 'confident', 'confronted', 'confused', 'confusing', 'conscious', 'considered', 'constipated', 'consulted', 'contacted', 'contagious', 'content', 'contented', 'continue', 'contributed', 'control', 'convinced', 'cook', 'cooked', 'cookies', 'cooking', 'cooks', 'cool', 'cooperate', 'cooperating', 'cop', 'copies', 'copilot', 'cops', 'copy', 'copyrighted', 'correct', 'corrected', 'cost', 'costs', 'couch', 'cough', 'coughed', 'coughing', 'could', \"could've\", \"couldn't\", 'count', 'counting', 'country', 'couple', 'courage', 'course', 'courteous', 'cousin', 'cousins', 'cover', 'cow', 'coward', 'cows', 'coyote', 'crafty', 'cranky', 'crazy', 'creaked', 'cream', 'created', 'creative', 'credible', 'creepy', 'cremated', 'crew', 'cried', 'cries', 'crime', 'cripple', 'critical', 'crook', 'cross', 'crowbar', 'crown', 'cruel', 'crushed', 'cry', 'crying', 'cuddling', 'cultured', 'cup', 'cured', 'curious', 'curly', 'curse', 'cursed', 'curses', 'curt', 'curtain', 'cuss', 'cut', 'cute', 'cutie', 'cycle', 'cycled', 'cynical', 'dad', 'daddy', 'daft', 'damaged', 'damp', 'dance', 'danced', 'dancer', 'dancers', 'dances', 'dancing', 'danger', 'dangerous', 'dare', 'dark', 'date', 'dating', 'dawn', 'day', 'daydreaming', 'dazed', 'dead', 'deaf', 'deal', 'dear', 'death', 'debt', 'deceitful', 'deceive', 'deceived', 'decide', 'decided', 'decision', 'decisive', 'declared', 'decline', 'decode', 'decorated', 'dedicated', 'deep', 'deeply', 'deer', 'defeated', 'defend', 'defensive', 'defiant', 'dehydrated', 'dejected', 'delicate', 'delicious', 'delighted', 'delirious', 'deliver', 'delusional', 'demand', 'demanding', 'denial', 'denied', 'dent', 'dentist', 'deny', 'depend', 'deported', 'depraved', 'depressed', 'deputy', 'deranged', 'deserve', 'deserved', 'deserves', 'designed', 'designers', 'desk', 'desperate', 'despise', 'despised', 'despises', 'dessert', 'detained', 'detective', 'detest', 'devastated', 'devious', 'devoted', 'diabetes', 'diabetic', 'dialed', 'diary', 'dice', 'did', \"didn't\", 'die', 'died', 'dies', 'diet', 'dieting', 'differ', 'different', 'difficult', 'digging', 'diligent', 'dimples', 'dinner', 'dinnertime', 'dinosaurs', 'diplomatic', 'dirt', 'dirty', 'disagree', 'disagreed', 'disappeared', 'disappointed', 'discreet', 'discuss', 'disgust', 'disgusted', 'disgusting', 'disgusts', 'dishes', 'dishonest', 'dislike', 'disliked', 'dislikes', 'disloyal', 'dismissed', 'disobeyed', 'dissatisfied', 'distracted', 'disturb', 'disturbed', 'ditch', 'ditched', 'dived', 'divorce', 'divorced', 'dizzy', 'do', 'doable', 'doctor', 'doctors', 'does', \"doesn't\", 'dog', \"dog's\", 'dogs', 'doing', 'doll', \"don't\", 'done', 'donkey', 'donut', 'donuts', 'doomed', 'door', 'doors', 'doubt', 'doubtful', 'doubts', 'dough', 'doughnut', 'doughnuts', 'down', 'downloaded', 'downstairs', 'dozed', 'dozing', 'draft', 'dragons', 'drank', 'draw', 'drawing', 'draws', 'dream', 'dreamer', 'dreaming', 'dreams', 'dreamy', 'drenched', 'dress', 'dressed', 'dresses', 'drew', 'drift', 'drill', 'drink', 'drinker', 'drinking', 'drinks', 'drive', 'driven', 'driver', 'drives', 'driving', 'drop', 'dropped', 'drove', 'drown', 'drowned', 'drowning', 'drowsy', 'drug', 'drugs', 'drum', 'drummer', 'drums', 'drunk', 'dry', 'dubious', 'ducked', 'dude', 'dug', 'dumb', 'dumbfounded', 'dump', 'dumped', 'dusting', 'duty', 'dwarf', 'dye', 'dyes', 'dying', 'dyslexic', 'each', 'eager', 'earlier', 'early', 'earned', 'ears', 'earthling', 'ease', 'eased', 'easily', 'east', 'easy', 'easygoing', 'eat', 'eaten', 'eating', 'eats', 'eccentric', 'ecstatic', 'edit', 'educated', 'effective', 'efficient', 'egg', 'eggplant', 'eggs', 'ego', 'eight', 'eighteen', 'elaborate', 'elbow', 'elderly', 'elected', 'elephants', 'elf', 'eloquent', 'else', 'elsewhere', 'elusive', 'embarrassed', 'embarrassing', 'emotional', 'emphatic', 'empty', 'end', 'ended', 'ends', 'enemies', 'enemy', 'energetic', 'engaged', 'engine', 'engineer', 'enjoy', 'enjoyed', 'enjoying', 'enjoys', 'enlisted', 'enormous', 'enough', 'enraged', 'ensued', 'enter', 'enticing', 'entranced', 'envelopes', 'envious', 'envy', 'epilepsy', 'equal', 'error', 'escape', 'escaped', 'escaping', 'ethical', 'euros', 'evasive', 'even', 'evening', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'evidence', 'evident', 'evil', 'ex', 'exaggerated', 'exaggerates', 'exaggerating', 'exam', 'excellent', 'excited', 'exciting', 'excuse', 'excused', 'executed', 'exercised', 'exercises', 'exercising', 'exhaled', 'exhausted', 'exhausting', 'exist', 'existed', 'exists', 'exit', 'expect', 'expected', 'expecting', 'expensive', 'expert', 'experts', 'explain', 'explained', 'explains', 'exuberant', 'eye', 'eyes', 'fabulous', 'face', 'faces', 'fact', 'facts', 'fad', 'fail', 'failed', 'fails', 'faint', 'fainted', 'fair', 'fairly', 'faith', 'faithful', 'fake', 'fakes', 'faking', 'fall', 'falling', 'falls', 'family', 'famished', 'famous', 'fan', 'fanatic', 'fanatical', 'fantastic', 'far', 'farm', 'farmer', 'farsighted', 'fascinate', 'fascinated', 'fascinating', 'fascist', 'fast', 'faster', 'fasting', 'fat', 'fate', 'father', 'fatter', 'fault', 'favor', 'fazed', 'fear', 'fearless', 'fed', 'fee', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'fence', 'fencing', 'fetch', 'fetched', 'fever', 'feverish', 'few', 'fiddler', 'fierce', 'fight', 'fighting', 'file', 'filming', 'filthy', 'finally', 'find', 'fine', 'finicky', 'finish', 'finished', 'fire', 'fired', 'firefly', 'fireman', 'first', 'fish', 'fishermen', 'fishing', 'fist', 'fit', 'five', 'fix', 'fixed', 'flag', 'flaky', 'flat', 'flatter', 'flattered', 'fleas', 'fled', 'flew', 'flexible', 'flies', 'flinched', 'floats', 'floor', 'flower', 'flowers', 'flu', 'flunk', 'flustered', 'flute', 'fly', \"fly's\", 'focus', 'focused', 'foggy', 'folded', 'follow', 'followed', 'food', \"food's\", 'fool', 'fooled', 'foolhardy', 'foolish', 'fools', 'foot', 'football', 'for', 'forbidden', 'forceful', 'foreigner', 'forgave', 'forget', 'forgetful', 'forgive', 'forgiven', 'forgives', 'forgot', 'fork', 'fortunate', 'forty', 'forward', 'fought', 'found', 'fox', 'fragile', 'frail', 'framed', 'frank', 'frankly', 'frantic', 'frat', 'freak', 'freaked', 'freaking', 'freckles', 'free', 'freezing', 'fresh', 'fried', 'friend', 'friendly', 'friends', 'frightened', 'frightens', 'from', 'frowned', 'froze', 'frozen', 'frugal', 'fruit', 'fruitcake', 'frustrated', 'full', 'fuming', 'fun', 'funerals', 'fungus', 'funny', 'furious', 'fuse', 'fussy', 'futile', 'futon', 'future', 'gain', 'gamble', 'gambler', 'game', 'games', 'gang', 'garden', 'gardener', 'gardeners', 'gardening', 'garlic', 'gas', 'gasped', 'gasping', 'gate', 'gave', 'gawking', 'gear', 'generous', 'genius', 'geniuses', 'gentle', 'gently', 'get', 'gets', 'getting', 'ghost', 'ghosts', 'giddy', 'gift', 'gifts', 'giggled', 'giggling', 'giraffe', 'girl', 'girls', 'give', 'given', 'gives', 'giving', 'glad', 'glanced', 'glared', 'glass', 'glasses', 'gloated', 'glove', 'gloves', 'glue', 'glutton', 'go', 'goal', 'goalie', 'goat', 'goes', 'going', 'gold', 'goldfish', 'golf', 'gone', 'good', 'goodbye', 'goodness', 'goofed', 'gorgeous', 'gossip', 'gossiping', 'gossips', 'got', 'gotten', 'grabbed', 'graceful', 'graduated', 'grass', 'grateful', 'grave', 'gray', 'grazed', 'great', 'greedy', 'green', 'grenade', 'grew', 'grieving', 'grimaced', 'grinned', 'grinning', 'grits', 'groaned', 'groaning', 'groggy', 'gross', 'grotesque', 'grouch', 'grouchy', 'grounded', 'group', 'grow', 'growled', 'grown', 'grows', 'grumbled', 'grumbling', 'grumpy', 'guarantee', 'guard', 'guess', 'guessed', 'guest', 'guests', 'guide', 'guilty', 'guitar', 'gullible', 'gum', 'gun', 'gunfire', 'guns', 'gut', 'guts', 'guy', 'guys', 'gymnast', 'habit', 'hacked', 'hacksaw', 'had', 'hailed', 'hailing', 'hair', \"hair's\", 'half', 'ham', 'hammer', 'hammered', 'hand', 'handed', 'handle', 'handmade', 'hands', 'handsome', 'hang', 'happen', 'happened', 'happening', 'happens', 'happy', 'harass', 'hard', 'harder', 'hare', 'harm', 'harmless', 'harp', 'has', \"hasn't\", 'hassle', 'hat', 'hate', 'hated', 'hates', 'have', \"haven't\", 'having', 'hay', 'he', \"he's\", 'head', 'headache', 'headed', 'heading', 'headstrong', 'healed', 'healthily', 'healthy', 'hear', 'heard', 'hearsay', 'heart', 'heartburn', 'heat', 'heavy', 'hedgehogs', 'held', 'hell', 'hello', 'help', 'helped', 'helpers', 'helpful', 'helping', 'helpless', 'helps', 'henhouse', 'henpecked', 'her', 'here', 'hermit', 'hero', 'heroes', 'heroic', 'hers', 'hesitant', 'hesitated', 'hesitating', 'hi', 'hibernate', 'hiccup', 'hiccups', 'hid', 'hide', 'hideous', 'hiding', 'high', 'higher', 'hiking', 'hilarious', 'him', 'himself', 'hint', 'hip', 'hire', 'hired', 'hiring', 'his', 'hiss', 'historian', 'historians', 'history', 'hit', 'hitting', 'hives', 'hobby', 'hockey', 'hogwash', 'hold', 'hole', 'holiday', 'holidays', 'hollow', 'home', 'homeless', 'homemade', 'homeschooled', 'homesick', 'homework', 'honest', 'honey', 'honked', 'honor', 'honorable', 'hope', 'hoped', 'hopeless', 'horrible', 'horrified', 'horse', 'horses', 'hospital', 'hospitals', 'hot', 'hotel', 'hotheaded', 'hottie', 'hour', 'house', 'housesitting', 'housewife', 'how', 'howled', 'hug', 'huge', 'hugged', 'human', 'humans', 'humble', 'humiliated', 'humiliating', 'hummed', 'humming', 'humorous', 'hunch', 'hung', 'hungover', 'hungry', 'hunt', 'hunter', 'hunting', 'hurried', 'hurry', 'hurt', 'hurting', 'hurts', 'husband', 'hydrated', 'hypocrisy', 'hypocrite', 'hysterical', 'iPod', 'ice', 'icy', 'idea', 'ideal', 'idiot', 'idiots', 'idle', 'idol', 'idolized', 'if', 'ignore', 'ignored', 'ill', 'illegal', 'illiterate', 'illogical', 'illusion', 'immature', 'immediately', 'immobile', 'immoral', 'immortal', 'immune', 'immunity', 'impartial', 'impassive', 'impatient', 'impolite', 'important', 'impossible', 'impressed', 'improbable', 'improve', 'improved', 'improving', 'improvise', 'improvised', 'impulsive', 'in', 'inadequate', 'inadvisable', 'inbox', 'incorrect', 'incredible', 'incurable', 'indignant', 'infected', 'inform', 'informed', 'inhaled', 'inhumane', 'injured', 'ink', 'innocent', 'innovative', 'insane', 'insects', 'insecure', 'inside', 'insincere', 'insisted', 'insolent', 'insomnia', 'inspired', 'instead', 'insult', 'insulted', 'insurance', 'intelligent', 'intend', 'intense', 'interest', 'interested', 'interesting', 'interfere', 'interfering', 'intern', 'interns', 'interpret', 'interrupt', 'intervened', 'into', 'intrigued', 'intrigues', 'inventive', 'invisible', 'invite', 'invited', 'inviting', 'involved', 'ironic', 'ironing', 'irrelevant', 'irritated', 'is', \"isn't\", 'isolated', 'issues', 'it', \"it'll\", \"it's\", 'itches', 'itchy', 'jacket', 'jail', 'jam', 'jar', 'jaw', 'jazz', 'jealous', 'jeans', 'jerk', 'jesuit', 'jittery', 'job', 'jobless', 'jobs', 'jock', 'jogging', 'join', 'joined', 'joints', 'joke', \"joke's\", 'jokes', 'joking', 'journal', 'journalist', 'judge', 'juice', 'jump', 'jumped', 'just', 'justice', 'karaoke', 'keep', 'keeps', 'kept', 'ketchup', 'key', 'keys', 'kick', 'kicked', 'kid', 'kidding', 'kids', 'kill', 'killed', 'killing', 'kind', 'kiss', 'kissed', 'kite', 'kites', 'kittens', 'kitty', 'klutz', 'knee', 'kneeled', 'kneeling', 'knelt', 'knew', 'knife', 'knits', 'knocking', 'knockout', 'know', 'known', 'knows', 'lab', 'label', 'lack', 'ladder', 'lady', 'laid', 'lake', 'landed', 'languages', 'laptop', 'large', 'lasagna', 'last', 'lasts', 'late', 'later', 'laugh', 'laughed', 'laughing', 'laughs', 'laundry', 'law', 'lawn', 'lawyer', 'lawyers', 'lay', 'lazy', 'lead', 'leaf', 'leaks', 'leaned', 'learn', 'learned', 'learning', 'learns', 'leave', 'leaves', 'leaving', 'lecherous', 'led', 'left', 'lefty', 'leg', 'legal', 'legend', 'legendary', 'legs', 'lemon', 'lenient', 'less', 'let', \"let's\", 'lethargic', 'letter', 'lettuce', 'leukemia', 'liar', 'liars', 'liberal', 'lie', 'lied', 'lies', 'life', 'lifeguard', 'lifeguards', 'lift', 'light', 'likable', 'like', 'likeable', 'liked', 'likes', 'limit', 'limp', 'limped', 'limping', 'line', \"line's\", 'lines', 'link', 'lion', 'lip', 'lips', 'list', 'listed', 'listen', 'listened', 'listening', 'listens', 'lit', 'literate', 'little', 'live', 'lived', 'lives', 'livid', 'lizards', 'llama', 'loaded', 'loan', 'lobby', 'located', 'locked', 'log', 'logical', 'lonely', 'loner', 'long', 'loo', 'look', 'looked', 'looking', 'looks', 'lose', 'loser', 'loses', 'losing', 'loss', 'lost', 'lot', 'lots', 'loud', 'louder', 'loudly', 'lovable', 'love', 'loveable', 'loved', 'lovely', 'loves', 'loving', 'low', 'loyal', 'lucid', 'luck', 'lucky', 'ludicrous', 'lunatic', 'lunch', 'lungs', 'lying', 'm', 'mad', 'made', 'madman', 'magic', 'magnificent', 'mahjong', 'maid', 'mail', 'make', 'makes', 'making', 'mama', 'man', 'manage', 'manager', 'managing', 'maniac', 'many', 'map', 'marine', 'mark', 'marmalade', 'married', 'martini', 'marvelous', 'mask', 'masochist', 'masseur', 'match', 'mates', 'math', 'matter', 'matters', 'mature', 'may', 'mayor', 'me', 'meal', 'mean', 'means', 'meant', 'meat', 'mechanic', 'medal', 'meddling', 'medic', 'meditating', 'meet', 'melons', 'melted', 'member', 'men', 'mention', 'mentioned', 'mentor', 'merciful', 'merciless', 'mermaids', 'mess', 'message', 'messy', 'met', 'metal', 'mic', 'mice', 'midnight', 'might', \"might've\", 'milk', 'milkman', 'mind', 'minded', 'mine', 'miner', 'minor', 'minus', 'minute', 'mirror', 'misbehave', 'miserable', 'miserly', 'misfit', 'misjudged', 'misleading', 'misled', 'misquoted', 'miss', 'missed', 'misses', 'missing', 'mistake', 'mistaken', 'mistakes', 'misunderstood', 'moaned', 'moaning', 'mobile', 'mock', 'modest', 'mole', 'mom', 'moment', 'mommy', 'money', 'monk', 'monkey', 'month', 'moody', 'moon', 'more', 'morning', 'moron', 'morons', 'mortal', 'mortified', 'mortifies', 'mother', 'motivated', 'mouse', 'mouth', 'move', 'moved', 'moves', 'movie', 'movies', 'moving', 'much', 'muffins', 'mug', 'mugged', 'murdered', 'music', 'musician', 'must', \"must've\", 'mute', 'muttering', 'my', 'myself', 'myth', 'nails', 'naive', 'naked', 'name', \"name's\", 'names', 'nap', 'nasty', 'nature', 'naughty', 'near', 'nearby', 'nearly', 'nearsighted', 'neat', 'necessary', 'neck', 'need', 'needed', 'needs', 'needy', 'negligent', 'negotiate', 'neighbors', 'nephew', 'nerve', 'nervous', 'nests', 'net', 'neurotic', 'neutral', 'never', 'new', 'newlyweds', 'news', 'next', 'nice', 'nicely', 'niece', 'night', 'nightmare', 'nights', 'nimble', 'ninja', 'no', 'nobody', 'nodded', 'nodding', 'noise', 'nonsense', 'nonsmoker', 'nonsmokers', 'noodles', 'noon', 'normal', 'normally', 'north', 'nose', 'nosey', 'nosy', 'not', 'notes', 'nothing', 'notice', 'noticed', 'notified', 'notify', 'novel', 'novels', 'now', 'numb', 'number', 'nurse', 'nutcase', 'nuts', 'oar', 'obedient', 'obese', 'obey', 'obeyed', 'obeys', 'object', 'objected', 'objection', 'objective', 'oblivious', 'obnoxious', 'oboe', 'obscene', 'observant', 'observing', 'obsessive', 'obsolete', 'obstinate', 'obvious', 'occupied', 'ocean', 'odd', 'of', 'off', 'offended', 'offensive', 'officer', 'often', 'oil', 'okay', 'old', 'older', 'oldest', 'olives', 'on', 'once', 'one', \"one's\", 'onions', 'online', 'only', 'open', 'opened', 'opera', 'oppose', 'opposed', 'optimist', 'optimistic', 'optimists', 'optional', 'options', 'or', 'orange', 'oranges', 'order', 'ordered', 'orders', 'organized', 'orphan', 'others', 'ought', 'our', 'ours', 'out', 'outdoors', 'outgoing', 'outlaw', 'outraged', 'outside', 'outsmarted', 'outspoken', 'oven', \"oven's\", 'over', 'overdo', 'overheard', 'overjoyed', 'overreacted', 'overreacting', 'oversleep', 'overslept', 'overweight', 'overworked', 'owe', 'owes', 'owl', 'own', 'owners', 'owns', 'oysters', 'p', 'pacifist', 'pacing', 'packing', 'paddling', 'page', 'pagoda', 'paid', 'pain', 'painless', 'paint', 'painted', 'painter', 'painting', 'paints', 'pajamas', 'pale', 'paled', 'pandas', 'panic', 'panicked', 'panicky', 'panting', 'pants', 'paper', 'paralyzed', 'paramedic', 'paraplegic', 'pardoned', 'parents', 'park', 'part', 'parties', 'partner', 'partners', 'party', \"party's\", 'pass', 'passed', 'past', 'pasta', 'pathetic', 'patient', 'patients', 'pattern', 'paused', 'pay', 'payday', 'paying', 'pays', 'peace', 'peach', 'peanuts', 'pear', 'pears', 'peas', 'peek', 'pen', 'pencil', 'pens', 'pensive', 'people', 'perceptive', 'perfect', 'perky', 'perplexed', 'persevering', 'person', 'personal', 'perverse', 'pet', 'petty', 'pheasant', 'phone', 'phoned', 'photogenic', 'photos', 'pianist', 'piano', 'pick', 'picks', 'picky', 'picnics', 'picture', 'pie', 'pigs', 'pill', 'pills', 'pilot', 'pilots', 'pinched', 'pint', 'pirate', 'pitch', 'pity', 'pizza', \"pizza's\", 'pizzas', 'place', 'plan', 'plane', 'planet', 'plans', 'plant', 'plants', 'plastered', 'plastic', 'plate', 'play', 'played', 'player', 'playing', 'plays', 'plead', 'pleasant', 'please', 'pleased', 'plumber', 'pneumonia', 'poem', 'poems', 'poet', 'point', 'pointed', 'pointless', 'poison', 'poisoned', 'poisonous', 'poker', 'police', 'policeman', 'polite', 'politely', 'politician', 'politics', 'pompous', 'ponies', 'pony', 'pool', 'poor', 'poorly', 'pop', 'popcorn', 'popular', 'port', 'positive', 'possessed', 'possible', 'posted', 'pot', 'potatoes', 'potter', 'pounds', 'poured', 'pout', 'power', \"power's\", 'powerful', 'powerless', 'practical', 'practice', 'practicing', 'pray', 'prayed', 'praying', 'precautions', 'precious', 'precise', 'predicted', 'prefer', 'pregnant', 'prepaid', 'prepared', 'present', 'pressed', 'pressured', 'pretty', 'price', 'priest', 'prince', 'prison', 'prisoner', 'prisoners', 'privacy', 'prize', 'probably', 'problem', 'problems', 'proceed', 'professor', 'programmer', 'promise', 'promised', 'promoted', 'proof', 'prosper', 'protect', 'protected', 'protein', 'protest', 'protested', 'proud', 'prove', 'psychic', 'psycho', 'puking', 'pulse', 'pun', 'punched', 'punctual', 'punished', 'puppy', 'pure', 'purist', 'purpose', 'purr', 'push', 'pushed', 'pushing', 'pushy', 'put', 'puzzled', 'puzzles', 'qualified', 'quarreled', 'queasy', 'question', 'questions', 'quick', 'quicker', 'quickly', 'quiet', 'quietly', 'quit', 'quite', 'quitter', 'quitting', 'quote', 'rabbi', 'rabbits', 'raccoons', 'race', 'racist', 'radical', 'radio', 'radios', 'rain', 'raining', 'rains', 'rainy', 'raise', 'raised', 'ran', 'rang', 'rap', 'rapper', 'rare', 'rarely', 'rashly', 'rat', 'rather', 'rational', 'rats', 'ratted', 'raw', 'reach', 'reachable', 'read', 'reading', 'reads', 'ready', 'real', 'realist', 'realistic', 'reality', 'really', 'realtor', 'reason', 'reasonable', 'reasons', 'rebel', 'recall', 'receipt', 'recently', 'reckless', 'recluse', 'recognized', 'recommend', 'recorded', 'recover', 'recovered', 'recycle', 'red', 'redhead', 'redundant', 'reformed', 'refreshed', 'refugee', 'refugees', 'refund', 'refuse', 'refused', 'reggae', 'regret', 'regretful', 'regrettable', 'regularly', 'rejected', 'relatives', 'relax', 'relaxed', 'released', 'relented', 'reliable', 'relied', 'relief', 'relieved', 'reluctant', 'rely', 'remain', 'remarried', 'remember', 'remembered', 'remembers', 'remind', 'removed', 'rent', 'repair', 'replace', 'replaceable', 'replied', 'reply', 'reptiles', 'repulsive', 'reputable', 'request', 'require', 'reschedule', 'rescued', 'resentful', 'reserved', 'resign', 'resigned', 'resigning', 'resilient', 'resist', 'resisting', 'resolute', 'respect', 'respected', 'respects', 'respond', 'responded', 'rest', 'rested', 'resting', 'restless', 'retire', 'retired', 'retiring', 'return', 'returned', 'revenge', 'reviews', 'rewarded', 'rewrote', 'rice', 'rich', 'rid', 'riddle', 'riddles', 'ride', 'ridiculous', 'rifle', 'right', 'rights', 'rigid', 'ring', 'rip', 'ripped', 'rise', 'riser', 'risk', 'risks', 'risky', 'ritual', 'rituals', 'rival', 'river', 'road', 'robbed', 'robe', 'robot', 'rock', 'rocks', 'rode', 'rolls', 'romantic', 'roof', 'rookie', 'room', \"room's\", 'rope', 'rose', 'roses', 'rough', 'round', 'row', 'rub', 'rubbed', 'rubbish', 'rude', 'ruffian', 'rug', 'rugby', 'ruined', 'rule', 'rules', 'rum', 'run', 'runner', 'running', 'runs', 'rush', 'rushed', 'rushing', 'ruthless', 'sabotage', 'sad', 'saddened', 'sadly', 'safe', 'safely', 'said', 'sailor', 'sails', 'saint', 'sake', 'salad', 'salami', 'sale', 'salesman', 'salmon', 'salsa', 'salt', 'salty', 'same', 'samurai', 'sand', 'sane', 'sang', 'sank', 'sarcastic', 'sashimi', 'sat', 'satisfied', 'sauce', 'save', 'saved', 'saw', 'say', 'saying', 'says', 'scammed', 'scarce', 'scare', 'scared', 'scares', 'scaring', 'scary', 'school', 'scientist', 'scold', 'scolded', 'scooter', 'score', 'scored', 'scream', 'screamed', 'screaming', 'screams', 'screw', \"screw's\", 'scumbag', 'scurvy', 'sea', 'seafood', 'searched', 'searching', 'seasick', 'seat', \"seat's\", 'seated', 'sec', 'second', 'secret', 'secretive', 'secrets', 'security', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'sees', 'seldom', 'selected', 'selfish', 'sell', 'sells', 'send', 'senile', 'senior', 'sense', 'sensible', 'sensitive', 'sent', 'separated', 'serious', 'servant', 'serve', 'served', 'set', 'settled', 'seven', 'seventeen', 'sewing', 'sexist', 'sexy', 'shadow', 'shaken', 'shaking', 'shall', 'shallow', 'sham', 'shame', 'shameless', 'share', 'shark', 'sharp', 'shave', 'shaved', 'shaving', 'she', 'sheep', 'shiny', 'ship', 'shirt', 'shirtless', 'shivered', 'shivering', 'shock', 'shocked', 'shoes', 'shook', 'shoot', 'shooting', 'shopkeeper', 'shopping', 'shops', 'short', 'shortcut', 'shot', 'shots', 'should', \"shouldn't\", 'shout', 'shouted', 'shouting', 'shouts', 'show', 'showed', 'shower', 'showered', 'showers', 'showing', 'shrank', 'shrieked', 'shrugged', 'shuffled', 'shut', 'shutterbug', 'shy', 'shyly', 'sick', 'sickened', 'sickens', 'sicker', 'side', 'sieve', 'sigh', 'sighed', 'sighing', 'sign', 'silent', 'silently', 'silly', 'similar', 'simple', 'sincere', 'sing', 'singer', 'singers', 'singing', 'single', 'sings', 'sink', 'sinking', 'sinned', 'sipped', 'sips', 'sirens', 'sister', 'sisters', 'sit', 'sitting', 'six', 'size', 'skate', 'skating', 'skeptical', 'sketching', 'ski', 'skiing', 'skin', 'skinny', 'skip', 'skittish', 'skull', 'sky', 'slapped', 'slave', 'sleep', 'sleeping', 'sleeps', 'sleepy', 'sleet', 'sleeting', 'slender', 'slept', 'slim', 'slipped', 'slipping', 'slob', 'sloshed', 'slow', 'slowed', 'slower', 'slowly', 'sly', 'small', 'smaller', 'smart', 'smarter', 'smashed', 'smell', 'smelled', 'smells', 'smile', 'smiled', 'smiling', 'smoke', 'smoked', 'smoker', 'smokes', 'smoking', 'snack', 'snag', 'snail', 'sneaky', 'sneeze', 'sneezed', 'sneezing', 'sniffling', 'snob', 'snore', 'snores', 'snoring', 'snow', 'snowed', 'snowing', 'so', 'soaking', 'soap', 'sob', 'sobbed', 'sobbing', 'sober', 'soccer', 'sociable', 'socks', 'soda', 'sofa', 'soft', 'softly', 'sold', 'soldier', 'soldiers', 'solid', 'solved', 'some', 'somebody', 'someone', 'something', 'sometime', 'son', 'song', 'songs', 'sons', 'soon', 'sore', 'sorry', 'soul', 'soulmates', 'sound', 'sounded', 'soundly', 'sounds', 'soup', \"soup's\", 'sour', 'south', 'southpaw', 'space', 'spaghetti', 'spatula', 'speak', 'speaking', 'speaks', 'special', 'specific', 'sped', 'speech', 'speechless', 'spell', 'spent', 'spider', 'spiders', 'spies', 'spinach', 'spirited', 'spit', 'split', 'spoiled', 'spoke', 'spontaneous', 'spoons', 'sports', 'spotted', 'spring', 'spy', 'squabbling', 'square', 'squatting', 'squeak', 'squinted', 'stabbed', 'stable', 'staggered', 'stairs', 'stalled', 'stalling', 'stamina', 'stammered', 'stamp', 'stamps', 'stand', 'standing', 'stank', 'star', 'stare', 'stared', 'staring', 'stark', 'start', 'started', 'startled', 'starve', 'starved', 'starving', 'stay', 'stayed', 'staying', 'steal', 'steals', 'step', 'stepped', 'stern', 'stew', 'sticky', 'stiff', 'still', 'stingy', 'stink', 'stinks', 'stir', 'stoic', 'stole', 'stolen', 'stomach', 'stoned', 'stood', 'stop', 'stopped', 'stopping', 'stops', 'stories', 'storm', 'story', 'straight', 'stranded', 'strange', 'stranger', 'street', 'stressed', 'stressful', 'strict', 'stroke', 'strong', 'stronger', 'struggled', 'stubborn', 'stuck', 'student', 'students', 'studied', 'studies', 'studious', 'study', 'studying', 'stuff', 'stuffed', 'stung', 'stunned', 'stuntman', 'stupid', 'stutters', 'succeed', 'succeeded', 'successful', 'such', 'suddenly', 'sue', 'sued', 'suffer', 'suffering', 'sufficient', 'sugar', 'suggested', 'suggestions', 'suicidal', 'suit', 'suitable', 'suits', 'summer', 'sun', 'sunflower', 'sunny', 'sunsets', 'suntan', 'superb', 'supper', 'supply', 'support', 'supported', 'suppose', 'sure', 'surfer', 'surfing', 'surgery', 'surprise', 'surprised', 'surprises', 'surrender', 'surrendered', 'surrounded', 'survive', 'survived', 'surviving', 'sushi', 'suspect', 'suspected', 'suspended', 'suspicious', 'swam', 'swearing', 'swears', 'sweat', 'sweated', 'sweating', 'sweaty', 'sweet', 'sweets', 'swim', 'swimming', 'swims', 'swindled', 'switch', 'sword', 'swore', 'sympathize', 'sympathized', 'table', 'tactful', 'tactless', 'tag', 'tagged', 'tailor', 'tailors', 'take', 'takes', 'taking', 'talent', 'talented', 'talk', 'talkative', 'talked', 'talking', 'talks', 'tall', 'taller', 'tallest', 'tango', 'tank', 'tape', 'tasered', 'taste', 'tasted', 'tastes', 'tasty', 'tattoo', 'taught', 'taxes', 'taxi', \"taxi's\", 'taxpayers', 'tea', \"tea's\", 'teach', 'teacher', 'teaches', 'team', 'tears', 'tease', 'teased', 'teasing', 'teenager', 'teeth', 'tell', 'tells', 'temp', 'tempt', 'tempted', 'ten', 'tenacious', 'tennis', 'tenor', 'tense', 'terminal', 'terrible', 'terrific', 'terrified', 'terrifying', 'test', 'testify', 'tests', 'texted', 'texting', 'than', 'thank', 'thanked', 'thanks', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'then', 'theory', 'therapist', 'therapy', 'there', 'these', 'they', 'thief', 'thieves', 'thin', 'things', 'think', 'thinking', 'thirsty', 'thirteen', 'thirty', 'thirtyish', 'this', 'thorough', 'those', 'thought', 'threat', 'three', 'threw', 'thrilled', 'thrilling', 'throat', 'through', 'throw', 'ticket', 'tickled', 'tickles', 'tickling', 'ticklish', 'tidied', 'tidy', 'tie', 'tied', 'tigers', 'tight', 'till', 'time', \"time's\", 'times', 'timid', 'timing', 'tiny', 'tip', 'tipsy', 'tire', \"tire's\", 'tired', 'tireless', 'tires', 'tissue', 'to', 'toaster', 'today', 'toes', 'tofu', 'together', 'told', 'tolerant', 'tomatoes', 'tomboy', 'tomorrow', 'tongue', 'tonight', 'too', 'took', 'tool', 'tools', 'tooth', 'tormented', 'tortured', 'touch', 'touched', 'touching', 'touchy', 'tough', 'tour', 'tourist', 'towel', 'tower', 'town', 'townie', 'toy', 'tragic', 'train', 'training', 'trains', 'traitor', 'traitors', 'translate', 'translator', 'transparent', 'trap', 'trapped', 'trash', 'travel', 'traveling', 'treat', 'tree', 'trees', 'trembling', 'trick', 'tricked', 'tried', 'tries', 'trip', 'tripped', 'trips', 'trophy', 'trouble', 'troubled', 'truck', 'trucker', 'true', 'truly', 'trust', 'trusted', 'trusts', 'truth', 'truthful', 'try', 'trying', 'tub', 'tulips', 'tuna', 'tune', 'turn', 'turned', 'turtles', 'twelve', 'twice', 'twin', 'twins', 'twitches', 'two', 'type', 'types', 'typical', 'ugly', 'ulcer', 'umbrella', 'unafraid', 'unarmed', 'unbiased', 'uncertain', 'uncle', 'undecided', 'undefeated', 'under', 'underage', 'understand', 'understands', 'understood', 'undo', 'undressing', 'uneasy', 'unemployed', 'unethical', 'unfair', 'unfazed', 'unfortunate', 'unhappy', 'unharmed', 'unhurt', 'unimpressed', 'uninsured', 'unkind', 'unlikely', 'unlocked', 'unlucky', 'unmarried', 'unmoved', 'unnecessary', 'unnerved', 'unpacking', 'unpopular', 'unprejudiced', 'unrelated', 'unreliable', 'unsettled', 'unshaven', 'unsociable', 'unstable', 'unsure', 'untalented', 'untidy', 'untrue', 'unusual', 'unwell', 'up', 'updated', 'upset', 'upsetting', 'upstairs', 'urgent', 'us', 'use', 'used', 'useful', 'useless', 'uses', 'using', 'usually', 'vacation', 'vacuum', 'vague', 'vain', 'vampire', 'vampires', 'van', 'vanished', 'vegan', 'veggies', 'vengeance', 'very', 'vet', 'veteran', 'vicious', 'victorious', 'video', 'view', 'vigilant', 'violence', 'violent', 'violin', 'visa', 'vision', 'visit', 'visited', 'visitors', 'vitamins', 'vodka', 'voice', 'voices', 'volunteered', 'volunteers', 'vomited', 'vomiting', 'vote', 'voted', 'waffles', 'wait', 'waited', 'waiter', 'waiting', 'wake', 'waking', 'walk', 'walked', 'walking', 'walks', 'wallet', \"wallet's\", 'wander', 'wandered', 'wanna', 'want', 'wanted', 'wants', 'war', 'warm', 'warmly', 'warn', 'warned', 'wary', 'was', 'wash', 'washed', 'washing', \"wasn't\", 'wasted', 'wasteful', 'watch', 'watched', 'watches', 'watchful', 'watching', 'water', 'waved', 'wavering', 'way', 'we', \"we'd\", \"we're\", 'weak', 'weakening', 'weaker', 'weakling', 'wealthy', 'weapon', 'wear', 'wears', 'weary', 'website', 'weddings', 'week', 'weight', 'weird', 'weirdo', 'welcome', 'welcomed', 'well', 'went', 'wept', 'were', \"weren't\", 'west', 'westerns', 'wet', 'wets', 'what', \"what's\", 'wheezing', 'when', 'where', \"where's\", 'while', 'whimpering', 'whining', 'whisky', 'whispered', 'whistle', 'whistled', 'whistling', 'white', 'who', \"who's\", 'whom', 'why', 'wicked', 'wide', 'widened', 'widow', 'widower', 'wife', 'wig', 'will', 'willing', 'wimp', 'win', 'wind', 'window', 'windows', 'windy', 'wine', 'wines', 'wings', 'winked', 'winners', 'winning', 'wins', 'winter', 'wise', 'wisely', 'wish', 'witch', 'with', 'without', 'witness', 'witty', 'wizard', 'wobbly', 'woke', 'wolf', 'woman', 'women', 'won', \"won't\", 'wonder', 'wondered', 'wonderful', 'woods', 'woozy', 'word', 'wore', 'work', 'worked', 'working', 'works', 'world', 'worn', 'worried', 'worry', 'worse', 'worships', 'worth', 'worthless', 'would', \"wouldn't\", 'wound', 'wounded', 'wrap', 'wrench', 'wrist', 'write', 'writer', 'writes', 'writing', 'wrong', 'wronged', 'wrote', 'yawn', 'yawned', 'yawning', 'year', 'years', 'yell', 'yelled', 'yelling', 'yellow', 'yen', 'yes', 'yesterday', 'yet', 'yodeler', 'yoga', 'yolks', 'you', \"you'd\", \"you're\", \"you've\", 'young', 'younger', 'youngest', 'your', 'yours', 'yourself', 'yourselves', 'zebra', 'zip', 'zoo', 'zoomed']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Importing our translations\n",
    "# for example: \"spa.txt\" or \"spa-eng/spa.txt\"\n",
    "data_path = \"deu.txt\"\n",
    "\n",
    "# Defining lines as a list of each line\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  lines = f.read().split('\\n')\n",
    "\n",
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "# Adjust the number of lines so that\n",
    "# preprocessing doesn't take too long\n",
    "for line in lines[:23000]:\n",
    "  # Input and target sentences are separated by tabs\n",
    "  input_doc, target_doc = line.split('\\t')[:2]\n",
    "  # Appending each input sentence to input_docs\n",
    "  input_docs.append(input_doc)\n",
    "\n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  # Redefine target_doc below\n",
    "  # and append it to target_docs:\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "\n",
    "  # Now we split up each sentence into words\n",
    "  # and add each unique word to our vocabulary set\n",
    "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    # print(token)\n",
    "    # Add your code here:\n",
    "    if token not in input_tokens:\n",
    "      input_tokens.add(token)\n",
    "  for token in target_doc.split():\n",
    "    # print(token)\n",
    "    # And here:\n",
    "    if token not in target_tokens:\n",
    "      target_tokens.add(token)\n",
    "\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "# Create num_encoder_tokens and num_decoder_tokens:\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
    "\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "\n",
    "  for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "    # Assign 1. for the current line, timestep, & word\n",
    "    # in encoder_input_data:\n",
    "    encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "\n",
    "  for timestep, token in enumerate(target_doc.split()):\n",
    "\n",
    "    decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "    if timestep > 0:\n",
    "\n",
    "      decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n",
    "\n",
    "# print out those value here:\n",
    "print(list(input_features_dict.keys())[:50], reverse_target_features_dict[50])\n",
    "print(input_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc7921",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0206c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, None, 4328)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, None, 6881)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 256),        4695040     ['input_5[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  7309312     ['input_6[0][0]',                \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 6881)   1768417     ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,772,769\n",
      "Trainable params: 13,772,769\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "368/368 [==============================] - 269s 723ms/step - loss: 1.5136 - accuracy: 0.0780 - val_loss: 1.5052 - val_accuracy: 0.0840\n",
      "Epoch 2/100\n",
      "368/368 [==============================] - 289s 786ms/step - loss: 1.2978 - accuracy: 0.0938 - val_loss: 1.4273 - val_accuracy: 0.0930\n",
      "Epoch 3/100\n",
      "368/368 [==============================] - 265s 719ms/step - loss: 1.2311 - accuracy: 0.1039 - val_loss: 1.3620 - val_accuracy: 0.1081\n",
      "Epoch 4/100\n",
      "368/368 [==============================] - 283s 769ms/step - loss: 1.1221 - accuracy: 0.1226 - val_loss: 1.2363 - val_accuracy: 0.1320\n",
      "Epoch 5/100\n",
      "260/368 [====================>.........] - ETA: 1:15 - loss: 1.0344 - accuracy: 0.1363"
     ]
    }
   ],
   "source": [
    "# Import tensorflow and keras layers\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# UNCOMMENT THE TWO LINES BELOW IF YOU ARE GETTING ERRORS ON A MAC\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Choose a dimensionality\n",
    "latent_dim = 256\n",
    "\n",
    "# Choose a batch size\n",
    "# and a number of epochs:\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "\n",
    "# Encoder training setup\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# Decoder training setup:\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Building the training model:\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "print(\"Model summary:\\n\")\n",
    "training_model.summary()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Compile the model:\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print(\"Training the model:\\n\")\n",
    "# Train the model:\n",
    "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "\n",
    "training_model.save('training_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d2647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Duck!\n",
      "Decoded sentence:  Kein dich ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Stay.\n",
      "Decoded sentence:  Mach ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence:  Warte ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Begin.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence:  Iss es ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence:  Iss es ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence:  Mach dich ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I hid.\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I hid.\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence:  Ich . <END>\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence:  Ich . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I won.\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence:  Problem ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence:  Mach dich ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence:  ! ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence:  ! ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Sorry?\n",
      "Decoded sentence:  Wer ? <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Ask me.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Ask me.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Ask me.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Buy it.\n",
      "Decoded sentence:  Gib es ! <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence:  Kein nicht ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence:  Iss es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence:  Iss Sie . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence:  Iss Sie . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence:  Iss Sie . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence:  Danke ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence:  Mach dich ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence:  ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence:  ! <END>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence:  ? <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence:  ? <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence:  ? <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence:  Er ist . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence:  Er ist . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence:  Mach ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence:  Mach ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence:  Nimm Sie . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I care.\n",
      "Decoded sentence:  Ich ich es . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I fled.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I fled.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I lied.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence:  Ich habe es . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I sang.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I spit.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I spit.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: I swim.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: I wept.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: I wept.\n",
      "Decoded sentence:  Ich habe . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence:  Ich bin ein . <END>\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence:  Ich bin ein . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence:  Ich bin ein . <END>\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence:  Ich bin ein . <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: I'm up.\n",
      "Decoded sentence:  Ich bin . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "-\n",
      "Input sentence: I'm up.\n",
      "Decoded sentence:  Ich bin . <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence:  Sie . <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence:  Echt ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence:  Echt ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence:  Echt ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence:  Echt ! <END>\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence:  Echt ! <END>\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence:  Echt ? <END>\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence:  Echt ? <END>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "training_model = load_model('training_model.h5')\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "def decode_sequence(test_input):\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model.predict(test_input)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "  # Populate the first token of target sequence with the start token.\n",
    "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "\n",
    "  # Sampling loop for a batch of sequences\n",
    "  # (to simplify, here we assume a batch of size 1).\n",
    "  decoded_sentence = ''\n",
    "\n",
    "  stop_condition = False\n",
    "  while not stop_condition:\n",
    "    # Run the decoder model to get possible \n",
    "    # output tokens (with probabilities) & states\n",
    "    output_tokens, hidden_state, cell_state = decoder_model.predict(\n",
    "      [target_seq] + states_value)\n",
    "\n",
    "    # Choose token with highest probability\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "    decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop token.\n",
    "    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "      stop_condition = True\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Update states\n",
    "    states_value = [hidden_state, cell_state]\n",
    "\n",
    "  return decoded_sentence\n",
    "\n",
    "\n",
    "# CHANGE RANGE (NUMBER OF TEST SENTENCES TO TRANSLATE) AS YOU PLEASE\n",
    "for seq_index in range(100):\n",
    "  test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(test_input)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_docs[seq_index])\n",
    "  print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b605879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
